{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_iypmaoAlE7",
        "outputId": "9f5bf036-1385-4ee5-895d-cfef0e61f366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "frVk9wWi4qWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dc0788-13ce-4623-fb18-de58be2bc9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 개수: 240\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 경로 설정\n",
        "directory_path = \"/content/drive/MyDrive/JH/라벨링데이터/TL_damage/testdata\"\n",
        "\n",
        "# 디렉토리 내의 모든 파일 목록 가져오기\n",
        "file_list = os.listdir(directory_path)\n",
        "\n",
        "# 파일만의 개수를 세기 위한 카운트 변수 초기화\n",
        "file_count = 0\n",
        "\n",
        "# 모든 파일 목록에 대해 반복\n",
        "for file_name in file_list:\n",
        "    # 파일 경로 생성\n",
        "    file_path = os.path.join(directory_path, file_name)\n",
        "\n",
        "    # 파일인 경우 카운트\n",
        "    if os.path.isfile(file_path):\n",
        "        file_count += 1\n",
        "\n",
        "# 파일 개수 출력\n",
        "print(f\"파일 개수: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qaom_1xf5V_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "85ba7f1a-5499-4d88-a9b7-9423b097f494"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bb23bd1ae143>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mjson_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjson_file_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from shutil import copyfile\n",
        "\n",
        "# 폴더 경로 설정\n",
        "json_directory = \"/content/drive/MyDrive/JH/라벨링데이터/TL_damage/traindata\"\n",
        "image_directory = \"/content/drive/MyDrive/JH/원천데이터/TS_damage/damage\"\n",
        "\n",
        "# 이미지와 레이블을 저장할 리스트\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for json_file_name in os.listdir(json_directory):\n",
        "    try:\n",
        "        if json_file_name.endswith('.json'):\n",
        "            json_file_path = os.path.join(json_directory, json_file_name)\n",
        "\n",
        "            # JSON 파일 읽기\n",
        "            with open(json_file_path, 'r') as json_file:\n",
        "                json_data = json.load(json_file)\n",
        "\n",
        "                # 이미지 파일 경로 생성\n",
        "                image_file_name = json_data[\"images\"][\"file_name\"]\n",
        "                image_file_path = os.path.join(image_directory, image_file_name)\n",
        "\n",
        "                # 이미지 파일이 존재하는지 확인\n",
        "                if os.path.exists(image_file_path):\n",
        "\n",
        "                    # 이미지 로드 및 전처리\n",
        "                    image = load_img(image_file_path, target_size=(224, 224))\n",
        "                    image_array = img_to_array(image)\n",
        "\n",
        "                    # 레이블 추출\n",
        "                    label = json_data[\"annotations\"][0][\"damage\"]\n",
        "\n",
        "                    # 이미지와 레이블 저장\n",
        "                    images.append(image_array)\n",
        "                    labels.append(label)\n",
        "\n",
        "                    # 레이블에 따라 이미지를 해당 디렉토리로 복사\n",
        "                    if label == \"Scratched\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/train/Scratched\"\n",
        "                    elif label == \"Breakage\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/train/Breakage\"\n",
        "                    elif label == \"Separated\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/train/Separated\"\n",
        "                    elif label == \"Crushed\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/train/Crushed\"\n",
        "                    else:\n",
        "                        print(f\"Unknown label: {label}. Skipping file: {json_file_name}\")\n",
        "                        continue\n",
        "\n",
        "                    os.makedirs(target_directory, exist_ok=True)  # 레이블 디렉토리 생성 (존재하지 않을 경우)\n",
        "                    copyfile(image_file_path, os.path.join(target_directory, image_file_name))\n",
        "\n",
        "                else:\n",
        "                    print(f\"이미지 파일을 찾을 수 없음: {image_file_path} (JSON 파일: {json_file_name})\")\n",
        "\n",
        "    except OSError as e:\n",
        "        # OSError가 발생하면 무시하고 계속 진행\n",
        "        print(f\"OSError: {e}. 파일 스킵 중: {json_file_name}\")\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from shutil import copyfile\n",
        "\n",
        "# 폴더 경로 설정\n",
        "json_directory = \"/content/drive/MyDrive/JH/라벨링데이터/TL_damage/testdata\"\n",
        "image_directory = \"/content/drive/MyDrive/JH/원천데이터/TS_damage/damage\"\n",
        "\n",
        "# 이미지와 레이블을 저장할 리스트\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for json_file_name in os.listdir(json_directory):\n",
        "    try:\n",
        "        if json_file_name.endswith('.json'):\n",
        "            json_file_path = os.path.join(json_directory, json_file_name)\n",
        "\n",
        "            # JSON 파일 읽기\n",
        "            with open(json_file_path, 'r') as json_file:\n",
        "                json_data = json.load(json_file)\n",
        "\n",
        "                # 이미지 파일 경로 생성\n",
        "                image_file_name = json_data[\"images\"][\"file_name\"]\n",
        "                image_file_path = os.path.join(image_directory, image_file_name)\n",
        "\n",
        "                # 이미지 파일이 존재하는지 확인\n",
        "                if os.path.exists(image_file_path):\n",
        "\n",
        "                    # 이미지 로드 및 전처리\n",
        "                    image = load_img(image_file_path, target_size=(224, 224))\n",
        "                    image_array = img_to_array(image)\n",
        "\n",
        "                    # 레이블 추출\n",
        "                    label = json_data[\"annotations\"][0][\"damage\"]\n",
        "\n",
        "                    # 이미지와 레이블 저장\n",
        "                    images.append(image_array)\n",
        "                    labels.append(label)\n",
        "\n",
        "                    # 레이블에 따라 이미지를 해당 디렉토리로 복사\n",
        "                    if label == \"Scratched\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/test/Scratched\"\n",
        "                    elif label == \"Breakage\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/test/Breakage\"\n",
        "                    elif label == \"Separated\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/test/Separated\"\n",
        "                    elif label == \"Crushed\":\n",
        "                        target_directory = \"/content/drive/MyDrive/JH/damage/test/Crushed\"\n",
        "                    else:\n",
        "                        print(f\"Unknown label: {label}. Skipping file: {json_file_name}\")\n",
        "                        continue\n",
        "\n",
        "                    os.makedirs(target_directory, exist_ok=True)  # 레이블 디렉토리 생성 (존재하지 않을 경우)\n",
        "                    copyfile(image_file_path, os.path.join(target_directory, image_file_name))\n",
        "\n",
        "                else:\n",
        "                    print(f\"이미지 파일을 찾을 수 없음: {image_file_path} (JSON 파일: {json_file_name})\")\n",
        "\n",
        "    except OSError as e:\n",
        "        # OSError가 발생하면 무시하고 계속 진행\n",
        "        print(f\"OSError: {e}. 파일 스킵 중: {json_file_name}\")\n",
        "        continue\n"
      ],
      "metadata": {
        "id": "LJYLmf6D7mOw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0HF7qHD3cuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_oTseWf84O5",
        "outputId": "84401cb3-b8ec-492f-c68d-8f6c0f69b996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 이미지 수: 960\n",
            "테스트 세트 이미지 수: 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc2ZnUth-dks",
        "outputId": "6134f1a5-581a-4ecb-a49b-fc283dbe6c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블의 종류: ['Scratched', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Crushed', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Separated', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Separated', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Separated', 'Breakage', 'Crushed', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Crushed', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Separated', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Crushed', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Crushed', 'Scratched', 'Scratched', 'Breakage', 'Crushed', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Crushed', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Crushed', 'Scratched', 'Separated', 'Breakage', 'Crushed', 'Breakage', 'Separated', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Breakage', 'Breakage', 'Separated', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Separated', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Crushed', 'Scratched', 'Separated', 'Crushed', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Crushed', 'Scratched', 'Separated', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Separated', 'Breakage', 'Crushed', 'Breakage', 'Breakage', 'Crushed', 'Crushed', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Separated', 'Scratched', 'Separated', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Crushed', 'Breakage', 'Crushed', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Separated', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Crushed', 'Separated', 'Breakage', 'Separated', 'Separated', 'Separated', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Breakage', 'Breakage', 'Crushed', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Breakage', 'Crushed', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Separated', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Crushed', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Crushed', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Separated', 'Breakage', 'Crushed', 'Breakage', 'Breakage', 'Crushed', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Separated', 'Crushed', 'Scratched', 'Breakage', 'Crushed', 'Separated', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Separated', 'Breakage', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Breakage', 'Breakage', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Separated', 'Separated', 'Crushed', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Separated', 'Scratched', 'Scratched', 'Separated', 'Scratched', 'Scratched', 'Scratched', 'Breakage', 'Scratched', 'Breakage', 'Breakage', 'Scratched', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Breakage', 'Separated', 'Separated', 'Breakage', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Crushed', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched', 'Scratched']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zu_uwtlC4WkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0f6050-d1cb-4cf6-a224-71459d53ffbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 960 files belonging to 4 classes.\n",
            "Found 240 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/JH/damage/train',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    seed=42,\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/JH/damage/test',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    seed=42,\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_func(image, label):\n",
        "    image = tf.cast(image / 255.0, tf.float32)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(preprocess_func)\n",
        "test_ds = test_ds.map(preprocess_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_funcc(image, label):\n",
        "    label = tf.one_hot(label, depth=4)\n",
        "    image = tf.cast(image / 255.0, tf.float32)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess_funcc)\n",
        "test_ds = test_ds.map(preprocess_funcc)\n"
      ],
      "metadata": {
        "id": "JOB3IX_QLZ3R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzublWiKqX09",
        "outputId": "e9486c22-082a-4c3d-b10c-0e4c87723cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24638852 (93.99 MB)\n",
            "Trainable params: 24585732 (93.79 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "15/15 [==============================] - 113s 2s/step - loss: 0.5988 - accuracy: 0.5760 - val_loss: 9.3256 - val_accuracy: 0.5542\n",
            "Epoch 2/150\n",
            "15/15 [==============================] - 6s 239ms/step - loss: 0.4047 - accuracy: 0.6500 - val_loss: 10.8846 - val_accuracy: 0.0875\n",
            "Epoch 3/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.3289 - accuracy: 0.7250 - val_loss: 2.8707 - val_accuracy: 0.0875\n",
            "Epoch 4/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.2956 - accuracy: 0.7604 - val_loss: 27.7231 - val_accuracy: 0.5542\n",
            "Epoch 5/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.2384 - accuracy: 0.8094 - val_loss: 11.5103 - val_accuracy: 0.5542\n",
            "Epoch 6/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.2105 - accuracy: 0.8188 - val_loss: 0.6379 - val_accuracy: 0.5542\n",
            "Epoch 7/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.1605 - accuracy: 0.8875 - val_loss: 0.7460 - val_accuracy: 0.5542\n",
            "Epoch 8/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.1358 - accuracy: 0.9073 - val_loss: 0.7605 - val_accuracy: 0.5542\n",
            "Epoch 9/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0941 - accuracy: 0.9365 - val_loss: 0.5597 - val_accuracy: 0.5542\n",
            "Epoch 10/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0839 - accuracy: 0.9312 - val_loss: 0.6525 - val_accuracy: 0.1333\n",
            "Epoch 11/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0570 - accuracy: 0.9646 - val_loss: 0.5465 - val_accuracy: 0.5542\n",
            "Epoch 12/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0911 - accuracy: 0.9385 - val_loss: 0.5183 - val_accuracy: 0.5542\n",
            "Epoch 13/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0785 - accuracy: 0.9469 - val_loss: 0.5796 - val_accuracy: 0.5542\n",
            "Epoch 14/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0483 - accuracy: 0.9677 - val_loss: 0.5238 - val_accuracy: 0.5542\n",
            "Epoch 15/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0376 - accuracy: 0.9750 - val_loss: 1.3207 - val_accuracy: 0.5542\n",
            "Epoch 16/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0435 - accuracy: 0.9729 - val_loss: 0.5371 - val_accuracy: 0.5542\n",
            "Epoch 17/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0372 - accuracy: 0.9729 - val_loss: 0.6731 - val_accuracy: 0.5542\n",
            "Epoch 18/150\n",
            "15/15 [==============================] - 5s 241ms/step - loss: 0.0258 - accuracy: 0.9823 - val_loss: 0.7278 - val_accuracy: 0.5542\n",
            "Epoch 19/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0301 - accuracy: 0.9865 - val_loss: 0.8489 - val_accuracy: 0.0875\n",
            "Epoch 20/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.8299 - val_accuracy: 0.0875\n",
            "Epoch 21/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.8323 - val_accuracy: 0.0875\n",
            "Epoch 22/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0062 - accuracy: 0.9948 - val_loss: 0.6908 - val_accuracy: 0.5542\n",
            "Epoch 23/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0107 - accuracy: 0.9917 - val_loss: 0.6594 - val_accuracy: 0.5542\n",
            "Epoch 24/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0091 - accuracy: 0.9917 - val_loss: 0.6679 - val_accuracy: 0.5542\n",
            "Epoch 25/150\n",
            "15/15 [==============================] - 5s 243ms/step - loss: 0.0056 - accuracy: 0.9958 - val_loss: 0.7001 - val_accuracy: 0.5542\n",
            "Epoch 26/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0039 - accuracy: 0.9969 - val_loss: 0.7365 - val_accuracy: 0.5542\n",
            "Epoch 27/150\n",
            "15/15 [==============================] - 5s 240ms/step - loss: 0.0036 - accuracy: 0.9958 - val_loss: 0.7493 - val_accuracy: 0.5542\n",
            "Epoch 28/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0032 - accuracy: 0.9969 - val_loss: 0.7564 - val_accuracy: 0.5542\n",
            "Epoch 29/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0047 - accuracy: 0.9958 - val_loss: 0.7936 - val_accuracy: 0.5542\n",
            "Epoch 30/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0038 - accuracy: 0.9958 - val_loss: 0.8275 - val_accuracy: 0.5542\n",
            "Epoch 31/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0028 - accuracy: 0.9958 - val_loss: 0.8708 - val_accuracy: 0.5542\n",
            "Epoch 32/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0027 - accuracy: 0.9958 - val_loss: 0.8902 - val_accuracy: 0.5542\n",
            "Epoch 33/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0029 - accuracy: 0.9937 - val_loss: 0.9073 - val_accuracy: 0.5542\n",
            "Epoch 34/150\n",
            "15/15 [==============================] - 5s 241ms/step - loss: 0.0026 - accuracy: 0.9958 - val_loss: 0.9240 - val_accuracy: 0.5542\n",
            "Epoch 35/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0027 - accuracy: 0.9969 - val_loss: 0.9426 - val_accuracy: 0.5542\n",
            "Epoch 36/150\n",
            "15/15 [==============================] - 5s 238ms/step - loss: 0.0025 - accuracy: 0.9948 - val_loss: 0.9484 - val_accuracy: 0.5542\n",
            "Epoch 37/150\n",
            "15/15 [==============================] - 5s 226ms/step - loss: 0.0025 - accuracy: 0.9958 - val_loss: 0.9584 - val_accuracy: 0.5542\n",
            "Epoch 38/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 0.9640 - val_accuracy: 0.5542\n",
            "Epoch 39/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0024 - accuracy: 0.9958 - val_loss: 0.9784 - val_accuracy: 0.5542\n",
            "Epoch 40/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0024 - accuracy: 0.9958 - val_loss: 0.9892 - val_accuracy: 0.5542\n",
            "Epoch 41/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0023 - accuracy: 0.9969 - val_loss: 0.9723 - val_accuracy: 0.5542\n",
            "Epoch 42/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0023 - accuracy: 0.9969 - val_loss: 0.9789 - val_accuracy: 0.5542\n",
            "Epoch 43/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0024 - accuracy: 0.9958 - val_loss: 0.9900 - val_accuracy: 0.5542\n",
            "Epoch 44/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0022 - accuracy: 0.9958 - val_loss: 1.0076 - val_accuracy: 0.5542\n",
            "Epoch 45/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0027 - accuracy: 0.9958 - val_loss: 1.0182 - val_accuracy: 0.5542\n",
            "Epoch 46/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.0270 - val_accuracy: 0.5542\n",
            "Epoch 47/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0020 - accuracy: 0.9969 - val_loss: 1.0450 - val_accuracy: 0.5542\n",
            "Epoch 48/150\n",
            "15/15 [==============================] - 5s 241ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 1.0233 - val_accuracy: 0.5542\n",
            "Epoch 49/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0027 - accuracy: 0.9969 - val_loss: 1.1851 - val_accuracy: 0.5542\n",
            "Epoch 50/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0027 - accuracy: 0.9969 - val_loss: 1.1750 - val_accuracy: 0.5542\n",
            "Epoch 51/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0028 - accuracy: 0.9969 - val_loss: 1.1707 - val_accuracy: 0.5542\n",
            "Epoch 52/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0021 - accuracy: 0.9979 - val_loss: 1.1708 - val_accuracy: 0.5542\n",
            "Epoch 53/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0026 - accuracy: 0.9948 - val_loss: 1.1669 - val_accuracy: 0.5542\n",
            "Epoch 54/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0023 - accuracy: 0.9958 - val_loss: 1.1555 - val_accuracy: 0.5542\n",
            "Epoch 55/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 1.1442 - val_accuracy: 0.5542\n",
            "Epoch 56/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0020 - accuracy: 0.9969 - val_loss: 1.1221 - val_accuracy: 0.5542\n",
            "Epoch 57/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0017 - accuracy: 0.9979 - val_loss: 1.1281 - val_accuracy: 0.5542\n",
            "Epoch 58/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0016 - accuracy: 0.9979 - val_loss: 1.1235 - val_accuracy: 0.5542\n",
            "Epoch 59/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.1191 - val_accuracy: 0.5542\n",
            "Epoch 60/150\n",
            "15/15 [==============================] - 5s 238ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 1.1328 - val_accuracy: 0.5542\n",
            "Epoch 61/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0036 - accuracy: 0.9969 - val_loss: 1.3031 - val_accuracy: 0.5542\n",
            "Epoch 62/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0045 - accuracy: 0.9958 - val_loss: 0.9755 - val_accuracy: 0.5542\n",
            "Epoch 63/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.1371 - accuracy: 0.9177 - val_loss: 1.2984 - val_accuracy: 0.0875\n",
            "Epoch 64/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.2993 - accuracy: 0.7448 - val_loss: 3.3658 - val_accuracy: 0.5542\n",
            "Epoch 65/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.2068 - accuracy: 0.8302 - val_loss: 1.5113 - val_accuracy: 0.0875\n",
            "Epoch 66/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.1136 - accuracy: 0.9302 - val_loss: 1.1577 - val_accuracy: 0.0875\n",
            "Epoch 67/150\n",
            "15/15 [==============================] - 5s 240ms/step - loss: 0.0813 - accuracy: 0.9500 - val_loss: 1.8404 - val_accuracy: 0.0875\n",
            "Epoch 68/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0426 - accuracy: 0.9792 - val_loss: 0.5650 - val_accuracy: 0.5542\n",
            "Epoch 69/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0524 - accuracy: 0.9646 - val_loss: 0.6696 - val_accuracy: 0.5542\n",
            "Epoch 70/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0418 - accuracy: 0.9698 - val_loss: 0.7680 - val_accuracy: 0.5542\n",
            "Epoch 71/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0400 - accuracy: 0.9698 - val_loss: 0.9687 - val_accuracy: 0.1000\n",
            "Epoch 72/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0171 - accuracy: 0.9896 - val_loss: 1.5091 - val_accuracy: 0.5542\n",
            "Epoch 73/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0142 - accuracy: 0.9875 - val_loss: 0.6734 - val_accuracy: 0.5542\n",
            "Epoch 74/150\n",
            "15/15 [==============================] - 5s 240ms/step - loss: 0.0104 - accuracy: 0.9927 - val_loss: 0.7255 - val_accuracy: 0.5542\n",
            "Epoch 75/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0087 - accuracy: 0.9937 - val_loss: 1.1875 - val_accuracy: 0.5542\n",
            "Epoch 76/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0126 - accuracy: 0.9896 - val_loss: 0.9300 - val_accuracy: 0.5542\n",
            "Epoch 77/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0133 - accuracy: 0.9896 - val_loss: 1.8251 - val_accuracy: 0.5542\n",
            "Epoch 78/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0162 - accuracy: 0.9844 - val_loss: 1.6670 - val_accuracy: 0.5542\n",
            "Epoch 79/150\n",
            "15/15 [==============================] - 5s 226ms/step - loss: 0.0202 - accuracy: 0.9865 - val_loss: 1.4908 - val_accuracy: 0.5542\n",
            "Epoch 80/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0300 - accuracy: 0.9844 - val_loss: 0.8464 - val_accuracy: 0.5542\n",
            "Epoch 81/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0309 - accuracy: 0.9823 - val_loss: 1.0441 - val_accuracy: 0.5542\n",
            "Epoch 82/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0465 - accuracy: 0.9729 - val_loss: 0.7999 - val_accuracy: 0.5542\n",
            "Epoch 83/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0379 - accuracy: 0.9667 - val_loss: 0.8069 - val_accuracy: 0.5542\n",
            "Epoch 84/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0273 - accuracy: 0.9792 - val_loss: 0.5465 - val_accuracy: 0.5542\n",
            "Epoch 85/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0165 - accuracy: 0.9896 - val_loss: 1.0685 - val_accuracy: 0.5542\n",
            "Epoch 86/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0118 - accuracy: 0.9906 - val_loss: 0.9860 - val_accuracy: 0.5542\n",
            "Epoch 87/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0063 - accuracy: 0.9927 - val_loss: 0.8567 - val_accuracy: 0.5542\n",
            "Epoch 88/150\n",
            "15/15 [==============================] - 5s 238ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.9637 - val_accuracy: 0.5542\n",
            "Epoch 89/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0044 - accuracy: 0.9948 - val_loss: 1.1377 - val_accuracy: 0.5542\n",
            "Epoch 90/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 0.0039 - accuracy: 0.9948 - val_loss: 1.3532 - val_accuracy: 0.5542\n",
            "Epoch 91/150\n",
            "15/15 [==============================] - 5s 229ms/step - loss: 0.0026 - accuracy: 0.9969 - val_loss: 1.6703 - val_accuracy: 0.5542\n",
            "Epoch 92/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.9829 - val_accuracy: 0.5542\n",
            "Epoch 93/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0024 - accuracy: 0.9969 - val_loss: 2.3016 - val_accuracy: 0.5542\n",
            "Epoch 94/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.6383 - val_accuracy: 0.5542\n",
            "Epoch 95/150\n",
            "15/15 [==============================] - 5s 243ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 2.8307 - val_accuracy: 0.5542\n",
            "Epoch 96/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0029 - accuracy: 0.9948 - val_loss: 3.1130 - val_accuracy: 0.5542\n",
            "Epoch 97/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 3.2508 - val_accuracy: 0.5542\n",
            "Epoch 98/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0021 - accuracy: 0.9979 - val_loss: 3.3614 - val_accuracy: 0.5542\n",
            "Epoch 99/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0019 - accuracy: 0.9969 - val_loss: 3.3921 - val_accuracy: 0.5542\n",
            "Epoch 100/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0017 - accuracy: 0.9979 - val_loss: 3.3950 - val_accuracy: 0.5542\n",
            "Epoch 101/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0020 - accuracy: 0.9969 - val_loss: 3.4214 - val_accuracy: 0.5542\n",
            "Epoch 102/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0015 - accuracy: 0.9979 - val_loss: 3.3499 - val_accuracy: 0.5542\n",
            "Epoch 103/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 3.2402 - val_accuracy: 0.5542\n",
            "Epoch 104/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0014 - accuracy: 0.9969 - val_loss: 3.1974 - val_accuracy: 0.5542\n",
            "Epoch 105/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 3.1614 - val_accuracy: 0.5542\n",
            "Epoch 106/150\n",
            "15/15 [==============================] - 5s 229ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 3.0935 - val_accuracy: 0.5542\n",
            "Epoch 107/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.9789 - val_accuracy: 0.5542\n",
            "Epoch 108/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0013 - accuracy: 0.9979 - val_loss: 2.8823 - val_accuracy: 0.5542\n",
            "Epoch 109/150\n",
            "15/15 [==============================] - 5s 240ms/step - loss: 0.0011 - accuracy: 0.9979 - val_loss: 2.7797 - val_accuracy: 0.5542\n",
            "Epoch 110/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 9.5071e-04 - accuracy: 0.9990 - val_loss: 2.6152 - val_accuracy: 0.5500\n",
            "Epoch 111/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 2.4597 - val_accuracy: 0.5500\n",
            "Epoch 112/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 0.0011 - accuracy: 0.9979 - val_loss: 2.3413 - val_accuracy: 0.5500\n",
            "Epoch 113/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 9.0076e-04 - accuracy: 0.9990 - val_loss: 2.3238 - val_accuracy: 0.5500\n",
            "Epoch 114/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 9.2681e-04 - accuracy: 1.0000 - val_loss: 2.2663 - val_accuracy: 0.5500\n",
            "Epoch 115/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 8.9170e-04 - accuracy: 0.9979 - val_loss: 2.2081 - val_accuracy: 0.5500\n",
            "Epoch 116/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.7188e-04 - accuracy: 0.9990 - val_loss: 2.1337 - val_accuracy: 0.5458\n",
            "Epoch 117/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.7096e-04 - accuracy: 0.9990 - val_loss: 2.0731 - val_accuracy: 0.5500\n",
            "Epoch 118/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 9.4290e-04 - accuracy: 0.9990 - val_loss: 1.9953 - val_accuracy: 0.5500\n",
            "Epoch 119/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 7.0291e-04 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.5542\n",
            "Epoch 120/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 7.3375e-04 - accuracy: 0.9990 - val_loss: 1.8278 - val_accuracy: 0.5625\n",
            "Epoch 121/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 8.6898e-04 - accuracy: 0.9979 - val_loss: 1.7624 - val_accuracy: 0.5750\n",
            "Epoch 122/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.0283e-04 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.5833\n",
            "Epoch 123/150\n",
            "15/15 [==============================] - 5s 239ms/step - loss: 8.4313e-04 - accuracy: 0.9979 - val_loss: 1.6279 - val_accuracy: 0.6083\n",
            "Epoch 124/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 6.9593e-04 - accuracy: 1.0000 - val_loss: 1.5614 - val_accuracy: 0.6292\n",
            "Epoch 125/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 0.0011 - accuracy: 0.9979 - val_loss: 1.5196 - val_accuracy: 0.6333\n",
            "Epoch 126/150\n",
            "15/15 [==============================] - 5s 235ms/step - loss: 8.4817e-04 - accuracy: 0.9990 - val_loss: 1.4860 - val_accuracy: 0.6375\n",
            "Epoch 127/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 8.1336e-04 - accuracy: 0.9990 - val_loss: 1.4564 - val_accuracy: 0.6500\n",
            "Epoch 128/150\n",
            "15/15 [==============================] - 5s 238ms/step - loss: 6.8947e-04 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.6542\n",
            "Epoch 129/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 8.3410e-04 - accuracy: 0.9990 - val_loss: 1.4196 - val_accuracy: 0.6625\n",
            "Epoch 130/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.4457e-04 - accuracy: 0.9990 - val_loss: 1.4160 - val_accuracy: 0.6750\n",
            "Epoch 131/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 7.3085e-04 - accuracy: 0.9990 - val_loss: 1.4068 - val_accuracy: 0.6833\n",
            "Epoch 132/150\n",
            "15/15 [==============================] - 5s 238ms/step - loss: 8.7491e-04 - accuracy: 0.9979 - val_loss: 1.3721 - val_accuracy: 0.6708\n",
            "Epoch 133/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 9.3218e-04 - accuracy: 0.9990 - val_loss: 1.3626 - val_accuracy: 0.6708\n",
            "Epoch 134/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 8.4786e-04 - accuracy: 0.9990 - val_loss: 1.3561 - val_accuracy: 0.6625\n",
            "Epoch 135/150\n",
            "15/15 [==============================] - 5s 239ms/step - loss: 7.6189e-04 - accuracy: 0.9990 - val_loss: 1.3572 - val_accuracy: 0.6583\n",
            "Epoch 136/150\n",
            "15/15 [==============================] - 5s 231ms/step - loss: 7.5228e-04 - accuracy: 0.9990 - val_loss: 1.3624 - val_accuracy: 0.6583\n",
            "Epoch 137/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 8.6531e-04 - accuracy: 0.9979 - val_loss: 1.3685 - val_accuracy: 0.6583\n",
            "Epoch 138/150\n",
            "15/15 [==============================] - 5s 233ms/step - loss: 6.8306e-04 - accuracy: 0.9990 - val_loss: 1.3730 - val_accuracy: 0.6708\n",
            "Epoch 139/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.6583e-04 - accuracy: 0.9990 - val_loss: 1.3759 - val_accuracy: 0.6708\n",
            "Epoch 140/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 6.9667e-04 - accuracy: 0.9990 - val_loss: 1.3765 - val_accuracy: 0.6750\n",
            "Epoch 141/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 8.6323e-04 - accuracy: 0.9979 - val_loss: 1.3813 - val_accuracy: 0.6750\n",
            "Epoch 142/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 8.7264e-04 - accuracy: 0.9990 - val_loss: 1.3873 - val_accuracy: 0.6750\n",
            "Epoch 143/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 6.2066e-04 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.6708\n",
            "Epoch 144/150\n",
            "15/15 [==============================] - 5s 239ms/step - loss: 6.5901e-04 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.6708\n",
            "Epoch 145/150\n",
            "15/15 [==============================] - 5s 232ms/step - loss: 7.0390e-04 - accuracy: 0.9990 - val_loss: 1.4067 - val_accuracy: 0.6708\n",
            "Epoch 146/150\n",
            "15/15 [==============================] - 5s 236ms/step - loss: 8.4818e-04 - accuracy: 0.9979 - val_loss: 1.4128 - val_accuracy: 0.6708\n",
            "Epoch 147/150\n",
            "15/15 [==============================] - 5s 237ms/step - loss: 8.0313e-04 - accuracy: 0.9990 - val_loss: 1.4114 - val_accuracy: 0.6667\n",
            "Epoch 148/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 7.6775e-04 - accuracy: 0.9990 - val_loss: 1.4133 - val_accuracy: 0.6667\n",
            "Epoch 149/150\n",
            "15/15 [==============================] - 5s 230ms/step - loss: 0.0010 - accuracy: 0.9979 - val_loss: 1.4118 - val_accuracy: 0.6625\n",
            "Epoch 150/150\n",
            "15/15 [==============================] - 5s 234ms/step - loss: 8.1641e-04 - accuracy: 0.9990 - val_loss: 1.4101 - val_accuracy: 0.6667\n"
          ]
        }
      ],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "def train_model(model, train_data, val_data, epochs):\n",
        "    # 모델 학습\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs, verbose=1)\n",
        "    return history\n",
        "\n",
        "history = train_model(model, train_ds, test_ds, epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pUeGJOy5cRfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdd1116-e067-48c2-e9bc-65508cd227c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Breakage: 0.00%\n",
            "Crushed: 0.00%\n",
            "Scratched: 100.00%\n",
            "Separated: 0.00%\n",
            "이미지의 손상: Scratched\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "damage_labels = {0: 'Breakage', 1: 'Crushed', 2: 'Scratched', 3: 'Separated'}\n",
        "\n",
        "def predict_damage(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    img_array /= 255.0\n",
        "\n",
        "    # 예측\n",
        "    predictions = model.predict(img_array)[0]\n",
        "    for i, score in enumerate(predictions):\n",
        "        print(f\"{damage_labels[i]}: {score*100:.2f}%\")  # 각 손상 유형의 확률을 출력\n",
        "\n",
        "    damage_idx = np.argmax(predictions)  # 가장 높은 확률을 가진 인덱스\n",
        "    damage = damage_labels[damage_idx]\n",
        "\n",
        "    return damage\n",
        "\n",
        "img_path = '/content/drive/MyDrive/JH/138624411-경미한-사고로-인한-자동차-앞-범퍼의-긁힘.jpg'\n",
        "predicted_damage = predict_damage(img_path, model)\n",
        "print(f\"이미지의 손상: {predicted_damage}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "sIYpVParwavO",
        "outputId": "b9e9e371-9120-4393-f441-14c539378862"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation maximum which has no identity",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-662c31577653>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 레이블을 one-hot 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlabels_train_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlabels_test_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m     \"\"\"\n\u001b[0;32m-> 2793\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2794\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B13czTawa3t",
        "outputId": "1866a13e-083f-49fc-e06d-89e32a8967cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(labels_train_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4LuNsEVwa6w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0XlWUz5wa9a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}